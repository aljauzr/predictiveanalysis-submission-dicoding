# -*- coding: utf-8 -*-
"""notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dnqTEaMzTUECDKnMWLtU7wAmfQKKUqO6

Import Library
---
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns
from sklearn.datasets import fetch_california_housing

"""Data Loading
---

Data yang Digunakan berasal dari dataset SKLearn yaitu California Housing
"""

data = fetch_california_housing(as_frame=True)
df = data.frame

print(df.shape)  # Output: (20640, 9)
df

"""Sebelum masuk ke tahapan EDA, mari kita telaah dulu variabel yang ada di dataset:
- MedInc: Median income di blok tersebut
- HouseAge: Umur median rumah
- AveRooms: Rata-rata jumlah kamar per rumah tangga
- AveBedrms: Rata-rata jumlah kamar tidur
- Population: Jumlah populasi di area
- AveOccup: Rata-rata jumlah penghuni per rumah
- Latitude: Koordinat geografis (lintang)
- Longitude: Koordinat geografis (bujur)
- MedHouseVal: Median nilai rumah di blok tersebut (dalam satuan $100.000) -> Fitur Target

Dikarenakan variabel Latitude dan Longitude merupakan variabel kesatuan, maka kita akan mengubahnya dulu menjadi variabel DistanceToLA, yaitu jarak rumah tersebut ke pusat kota (Los Angeles) agar model ML yang digunakan nantinya dapat menginterpretasikan variabel ini lebih mudah.
"""

city_lat = 34.05     # Los Angeles latitude
city_lon = -118.25   # Los Angeles longitude

def haversine(lat1, lon1, lat2, lon2):
    R = 6371  # Radius bumi dalam kilometer
    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])

    dlat = lat2 - lat1
    dlon = lon2 - lon1

    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2
    c = 2 * np.arcsin(np.sqrt(a))

    return R * c

data = fetch_california_housing(as_frame=True)
df = data.frame

# Tambahkan kolom jarak ke pusat kota
df['DistanceToLA'] = haversine(df['Latitude'], df['Longitude'], 34.05, -118.25)
df = df.drop(columns=['Latitude', 'Longitude'])
print("Tampilan data setelah dilakukan perubahan variabel:")
df

"""Exploratory Data Analysis (EDA)
---

**EDA - Deskripsi Variabel**
"""

df.info()

df.describe()

"""Tipe data pada semua variabel diketahui bertipe data numerik. Selain itu, terdapat value bernilai 0 (missing value) pada variabel **DistanceToLA**, maka dari itu perlu dilakukan penanganan missing value pada tahap berikutnya.

**EDA - Menangani Missing Value**
"""

DistanceToLA = (df.DistanceToLA == 0).sum()

print("Nilai 0 di kolom DistanceToLA ada: ", DistanceToLA)

df.loc[(df['DistanceToLA']==0)]

# Drop baris dengan nilai 'DistanceToLA' = 0
df = df.loc[(df[['DistanceToLA']]!=0).all(axis=1)]

# Cek ukuran data untuk memastikan baris sudah di-drop
df.shape

"""Missing value pada kolom DistanceToLA hanya ada 2, jumlah ini tergolong kecil maka dari itu diterapkan penghapusan baris pada kolom yang terdapat missing value tersebut.

**EDA - Menangani Outlier**

Setelah menangani missing value, selanjutnya kita akan menangani outlier (jika ada) pada tahap berikutnya. Pertama kita akan melakukan visualisasi data menggunakan boxplot untuk mengecek apakah ada outlier.
"""

sns.boxplot(x=df['MedInc'])

sns.boxplot(x=df['HouseAge'])

sns.boxplot(x=df['AveRooms'])

sns.boxplot(x=df['AveBedrms'])

sns.boxplot(x=df['Population'])

sns.boxplot(x=df['AveOccup'])

sns.boxplot(x=df['MedHouseVal'])

sns.boxplot(x=df['DistanceToLA'])

"""Setelah dilakukan visualisasi pada setiap variabel, ditemukan bahwa terdapat outlier pada variabel MedInc, AveRooms, AveBedrms, Population, AveOccup, dan MedHouseVal. Maka dari itu, kita akan melakukan teknik winsorizing, yaitu mengubah nilai outlier menjadi nilai ambang atas atau ambang bawah, sehingga tidak mengurangi data yang sudah ada."""

# Ambil hanya kolom numerikal
numeric_cols = df.select_dtypes(include='number').columns

# Hitung Q1, Q3, dan IQR untuk kolom numerikal
Q1 = df[numeric_cols].quantile(0.25)
Q3 = df[numeric_cols].quantile(0.75)
IQR = Q3 - Q1

# Hitung batas bawah dan atas
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Terapkan winsorizing: batasi nilai-nilai ekstrem
df[numeric_cols] = df[numeric_cols].clip(lower=lower_bound, upper=upper_bound, axis=1)

# Cek ukuran dataset (tidak berubah karena tidak menghapus baris)
df.shape

df.describe()

"""**EDA - Univariate Analysis**"""

numerical_features = ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'MedHouseVal', 'DistanceToLA']

df.hist(bins=50, figsize=(20,15))
plt.show()

"""**EDA - Multivariate Analysis**"""

# Numerical Features to Price
sns.pairplot(df, diag_kind = 'kde')

plt.figure(figsize=(10, 8))
correlation_matrix = df[numerical_features].corr().round(2)

# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

# Drop kolom Population karena memiliki tingkat korelasi yang sangat rendah
df.drop(['Population'], inplace=True, axis=1)
df.head()

"""Modelling
---

**Train-Test Split**
"""

from sklearn.model_selection import train_test_split

X = df.drop(["MedHouseVal"],axis =1)
y = df["MedHouseVal"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)
print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""**Standardisasi**"""

from sklearn.preprocessing import StandardScaler

numerical_features = ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'AveOccup', 'DistanceToLA']
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

# Siapkan dataframe untuk analisis model
models = pd.DataFrame(index=['train_mse', 'test_mse'],
                      columns=['KNN', 'RandomForest', 'Boosting'])

X_train[numerical_features].describe().round(4)

"""**KNN**"""

from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error

knn = KNeighborsRegressor(n_neighbors=10)
knn.fit(X_train, y_train)

models.loc['train_mse','knn'] = mean_squared_error(y_pred = knn.predict(X_train), y_true=y_train)

"""**Random Forest**"""

# Impor library yang dibutuhkan
from sklearn.ensemble import RandomForestRegressor

# buat model prediksi
RF = RandomForestRegressor(n_estimators=50, max_depth=16, random_state=55, n_jobs=-1)
RF.fit(X_train, y_train)

models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)

"""**Boosting Algorithm**"""

from sklearn.ensemble import AdaBoostRegressor

boosting = AdaBoostRegressor(learning_rate=0.05, random_state=55)
boosting.fit(X_train, y_train)
models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=boosting.predict(X_train), y_true=y_train)

"""Evaluasi
---
"""

# Lakukan scaling terhadap fitur numerik pada X_test sehingga memiliki rata-rata=0 dan varians=1
X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

# Buat variabel mse yang isinya adalah dataframe nilai mse data train dan test pada masing-masing algoritma
mse = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','Boosting'])

# Buat dictionary untuk setiap algoritma yang digunakan
model_dict = {'KNN': knn, 'RF': RF, 'Boosting': boosting}

# Hitung Mean Squared Error masing-masing algoritma pada data train dan test
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3

# Panggil mse
mse

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

prediksi = X_test.iloc[:1].copy()
pred_dict = {'y_true':y_test[:1]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)